# Neural Probabilistic Language Model

Implementation of the classical language model that was proposed back in 2003.<br>
Based on the n-gram language model and as an end-to-end model it proved that a neural network trained on predicting the following word given n-gram can be useful in embedding lexical context into vectors.<br>


![Screenshot 2024-11-12 171901](https://github.com/user-attachments/assets/5441a852-7b0c-45f0-b7c6-4c74f7b92d9a)
